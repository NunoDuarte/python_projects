{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:10.798788Z",
     "start_time": "2019-03-26T23:57:10.069265Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ea06f3a96943>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservoir implementation\n",
    "Adapted from https://github.com/FilippoMB/Reservoir-Computing-framework-for-multivariate-time-series-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:10.830425Z",
     "start_time": "2019-03-26T23:57:10.802499Z"
    }
   },
   "outputs": [],
   "source": [
    "class Reservoir(object):\n",
    "    \"\"\"\n",
    "    Build a reservoir and evaluate internal states\n",
    "    \n",
    "    Parameters:\n",
    "        n_internal_units = processing units in the reservoir\n",
    "        spectral_radius = largest eigenvalue of the reservoir matrix of connection weights\n",
    "        leak = amount of leakage in the reservoir state update (optional)\n",
    "        connectivity = percentage of nonzero connection weights (unused in circle reservoir)\n",
    "        input_scaling = scaling of the input connection weights\n",
    "        noise_level = deviation of the Gaussian noise injected in the state update\n",
    "        circle = generate determinisitc reservoir with circle topology\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_internal_units=100, spectral_radius=0.99, leak=None,\n",
    "                 connectivity=0.3, input_scaling=0.2, noise_level=0.01, circle=False):\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self._n_internal_units = n_internal_units\n",
    "        self._input_scaling = input_scaling\n",
    "        self._noise_level = noise_level\n",
    "        self._leak = leak\n",
    "\n",
    "        # Input weights depend on input size: they are set when data is provided\n",
    "        self._input_weights = None\n",
    "\n",
    "        # Generate internal weights\n",
    "        if circle:\n",
    "            self._internal_weights = self._initialize_internal_weights_Circ(\n",
    "                    n_internal_units,\n",
    "                    spectral_radius)\n",
    "        else:\n",
    "            self._internal_weights = self._initialize_internal_weights(\n",
    "                n_internal_units,\n",
    "                connectivity,\n",
    "                spectral_radius)\n",
    "\n",
    "\n",
    "    def _initialize_internal_weights_Circ(self, n_internal_units, spectral_radius):\n",
    "        \n",
    "        internal_weights = np.zeros((n_internal_units, n_internal_units))\n",
    "        internal_weights[0,-1] = spectral_radius\n",
    "        for i in range(n_internal_units-1):\n",
    "            internal_weights[i+1,i] = spectral_radius\n",
    "                \n",
    "        return internal_weights\n",
    "    \n",
    "    \n",
    "    def _initialize_internal_weights(self, n_internal_units,\n",
    "                                     connectivity, spectral_radius):\n",
    "\n",
    "        # Generate sparse, uniformly distributed weights.\n",
    "        internal_weights = sparse.rand(n_internal_units,\n",
    "                                       n_internal_units,\n",
    "                                       density=connectivity).todense()\n",
    "\n",
    "        # Ensure that the nonzero values are uniformly distributed in [-0.5, 0.5]\n",
    "        internal_weights[np.where(internal_weights > 0)] -= 0.5\n",
    "        \n",
    "        # Adjust the spectral radius.\n",
    "        E, _ = np.linalg.eig(internal_weights)\n",
    "        e_max = np.max(np.abs(E))\n",
    "        internal_weights /= np.abs(e_max)/spectral_radius       \n",
    "\n",
    "        return internal_weights\n",
    "\n",
    "\n",
    "    def _compute_state_matrix(self, X, n_drop=0):\n",
    "        N, T, _ = X.shape\n",
    "        previous_state = np.zeros((N, self._n_internal_units), dtype=float)\n",
    "\n",
    "        # Storage\n",
    "        state_matrix = np.empty((N, T - n_drop, self._n_internal_units), dtype=float)\n",
    "        for t in range(T):\n",
    "            current_input = X[:, t, :]\n",
    "\n",
    "            # Calculate state\n",
    "            state_before_tanh = self._internal_weights.dot(previous_state.T) + self._input_weights.dot(current_input.T)\n",
    "\n",
    "            # Add noise\n",
    "            state_before_tanh += np.random.rand(self._n_internal_units, N)*self._noise_level\n",
    "\n",
    "            # Apply nonlinearity and leakage (optional)\n",
    "            if self._leak is None:\n",
    "                previous_state = np.tanh(state_before_tanh).T\n",
    "            else:\n",
    "                previous_state = (1.0 - self._leak)*previous_state + np.tanh(state_before_tanh).T\n",
    "\n",
    "            # Store everything after the dropout period\n",
    "            if (t > n_drop - 1):\n",
    "                state_matrix[:, t - n_drop, :] = previous_state\n",
    "\n",
    "        return state_matrix\n",
    "\n",
    "\n",
    "    def get_states(self, X, n_drop=0, bidir=True):\n",
    "        N, T, V = X.shape\n",
    "        if self._input_weights is None:\n",
    "            self._input_weights = (2.0*np.random.binomial(1, 0.5 , [self._n_internal_units, V]) - 1.0)*self._input_scaling\n",
    "\n",
    "        # compute sequence of reservoir states\n",
    "        states = self._compute_state_matrix(X, n_drop)\n",
    "    \n",
    "        # reservoir states on time reversed input\n",
    "        if bidir is True:\n",
    "            X_r = X[:, ::-1, :]\n",
    "            states_r = self._compute_state_matrix(X_r, n_drop)\n",
    "            states = np.concatenate((states, states_r), axis=2)\n",
    "\n",
    "        return states\n",
    "    \n",
    "    def getReservoirEmbedding(self, X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False):\n",
    "\n",
    "        res_states = self.get_states(X, n_drop=5, bidir=True)\n",
    "\n",
    "\n",
    "        N_samples = res_states.shape[0]\n",
    "        res_states = res_states.reshape(-1, res_states.shape[2])                   \n",
    "        # ..transform..\n",
    "        if test:\n",
    "            red_states = pca.transform(res_states)\n",
    "        else:\n",
    "            red_states = pca.fit_transform(res_states)          \n",
    "        # ..and put back in tensor form\n",
    "        red_states = red_states.reshape(N_samples,-1,red_states.shape[1])  \n",
    "\n",
    "        coeff_tr = []\n",
    "        biases_tr = []   \n",
    "\n",
    "        for i in range(X.shape[0]):\n",
    "            ridge_embedding.fit(red_states[i, 0:-1, :], red_states[i, 1:, :])\n",
    "            coeff_tr.append(ridge_embedding.coef_.ravel())\n",
    "            biases_tr.append(ridge_embedding.intercept_.ravel())\n",
    "        print(np.array(coeff_tr).shape,np.array(biases_tr).shape)\n",
    "        input_repr = np.concatenate((np.vstack(coeff_tr), np.vstack(biases_tr)), axis=1)\n",
    "        return input_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:10.859387Z",
     "start_time": "2019-03-26T23:57:10.832419Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = scipy.io.loadmat('mat_files/dataset_gazeIST.mat')\n",
    "X = data['X']  \n",
    "Y = data['Y']\n",
    "\n",
    "print('X',np.shape(X))\n",
    "print('Y',np.shape(Y))\n",
    "Xte = data['Xte']\n",
    "Yte = data['Yte']\n",
    "\n",
    "# One-hot encoding for labels\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "Y = onehot_encoder.fit_transform(Y)\n",
    "Yte = onehot_encoder.transform(Yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define models for dimensionality reduction (pca), input representation creation (ridge_embedding), output layer (readout):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:10.869320Z",
     "start_time": "2019-03-26T23:57:10.863336Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=75)  \n",
    "ridge_embedding = Ridge(alpha=10, fit_intercept=True)\n",
    "readout = Ridge(alpha=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:11.207429Z",
     "start_time": "2019-03-26T23:57:10.873308Z"
    }
   },
   "outputs": [],
   "source": [
    "res = Reservoir(n_internal_units=450, spectral_radius=0.6, leak=0.6,\n",
    "                 connectivity=0.25, input_scaling=0.1, noise_level=0.01, circle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:13.939426Z",
     "start_time": "2019-03-26T23:57:11.209418Z"
    }
   },
   "outputs": [],
   "source": [
    "input_repr = res.getReservoirEmbedding(X,pca, ridge_embedding,  n_drop=5, bidir=True, test = False)\n",
    "input_repr_te = res.getReservoirEmbedding(Xte,pca, ridge_embedding,  n_drop=5, bidir=True, test = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect input representation to output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:14.006315Z",
     "start_time": "2019-03-26T23:57:13.942421Z"
    }
   },
   "outputs": [],
   "source": [
    "readout.fit(input_repr, Y)\n",
    "logits = readout.predict(input_repr_te)\n",
    "pred_class = np.argmax(logits, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:14.013233Z",
     "start_time": "2019-03-26T23:57:14.008244Z"
    }
   },
   "outputs": [],
   "source": [
    "true_class = np.argmax(Yte, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:14.042152Z",
     "start_time": "2019-03-26T23:57:14.016225Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_score(true_class, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-26T23:57:14.066088Z",
     "start_time": "2019-03-26T23:57:14.046143Z"
    }
   },
   "outputs": [],
   "source": [
    "f1_score(true_class, pred_class, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
